{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd3a4e9-5e71-4d5f-8582-c2141e186370",
   "metadata": {},
   "source": [
    "# SMAI Assignment - 2\n",
    "\n",
    "## Question - `3` : Multinomial NaÃ¯ve Bayes\n",
    "\n",
    "| | |\n",
    "|- | -|\n",
    "| Course | Statistical Methods in AI |\n",
    "| Release Date | `16.02.2023` |\n",
    "| Due Date | `24.02.2023` |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08fcb7b3-fc94-4ce9-b058-0b26a3b93f7a",
   "metadata": {},
   "source": [
    "This question will have you working and experimenting with the Multinomial NaÃ¯ve Bayes classifier. Initially, you will transform the given data in csv file to count matrix, then calculate the priors. Use those priors to compute likelihoods according to Multinomial Naive Bayes and then classify the test data. Please note that use of `sklearn` implementations is only for the final question of the assignment, for other doubts regarding libraries you can reach out to the TAs.\n",
    "\n",
    "The dataset is about `Spam SMS`. There is 1 attribute that is the `message`, and the class label which could be `spam` or `ham`. The data is present in `spam.csv`. It contains about 5-6000 samples.\n",
    "For your convinience the data is already pre-processed and loaded, but I suggest you to just take a look at the code for your own knowledge, and parts vectorization is left up to you which could be easily done with the help of the given example code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8a96d4-58f3-4360-b6ae-a02405ffdddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630170e6-57f8-4dae-b644-ab275a3f53a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading text-based data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2430d4f2-e3ed-4e09-9e50-a446889d58cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file into pandas using a relative path\n",
    "\n",
    "df = pd.read_csv(\"./spam.csv\", encoding='latin-1')\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbeec1-2b88-4af3-b8c6-906936938951",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "- Our main issue with our data is that it is all in text format (strings). The classification algorithms that we usally use need some sort of numerical feature vector in order to perform the classification task. There are actually many methods to convert a corpus to a vector format. The simplest is the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "- As a first step, let's write a function that will split a message into its individual words and return a list. We'll also remove very common words, ('the', 'a', etc..). To do this we will take advantage of the NLTK library. It's pretty much the standard library in Python for processing text and has a lot of useful features. We'll only use some of the basic ones here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d736a35c-e849-4029-bee7-42a31f7d0b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gagan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed807b40-7762-4968-b546-2f72817beed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go jurong point crazy Available bugis n great ...\n",
       "1   ham                              Ok lar Joking wif oni\n",
       "2  spam  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3   ham                    dun say early hor c already say\n",
       "4   ham             Nah think goes usf lives around though"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'] = df.message.apply(text_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad88d89f-1452-4e7a-9f9c-cb1094f890d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazy Available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go jurong point crazy Available bugis n great ...\n",
       "1      0                              Ok lar Joking wif oni\n",
       "2      1  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3      0                    dun say early hor c already say\n",
       "4      0             Nah think goes usf lives around though"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'ham':0, 'spam':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22eddba-546a-4e97-b013-2906e90946b7",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77f6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectoriseX(X):\n",
    "    cv = CountVectorizer()\n",
    "    X = cv.fit_transform(X).toarray()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f859993a-2b29-4baf-a168-117151ed240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5572,)\n",
      "y: (5572,)\n",
      "\n",
      "X_train: (4179,)\n",
      "y_train: (4179,)\n",
      "\n",
      "X_test: (1393,)\n",
      "y_test: (1393,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.message\n",
    "y = df.label\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')\n",
    "print()\n",
    "\n",
    "# X = vectoriseX(X)\n",
    "y = y.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print()\n",
    "\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6deffc-0424-4cb6-85d2-eb74f97e8cdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper code / Example code for Representing text as Numerical data using Sci-kit learn\n",
    "\n",
    "ðŸ“Œ From the scikit-learn documentation:\n",
    "- Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "- We will use CountVectorizer to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1309604c-b9c1-4910-ab60-432f7e12824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'Please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fde24ff-b303-4526-899d-fb902eabc1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cab', 'call', 'me', 'please', 'tonight', 'you'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "simple_train = vect.fit_transform(simple_train)\n",
    "\n",
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576f6e05-6e94-45a1-96cc-3e694cc971d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cab', 'call', 'me', 'please', 'tonight', 'you'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aef831c-50f0-4723-a04a-27af774f0542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa523614-ff0d-4f22-b8f2-4505e33a2460",
   "metadata": {},
   "source": [
    "In this scheme, features and samples are defined as follows:\n",
    "\n",
    "- Each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "- The vector of all the token frequencies for a given document is considered a multivariate sample.\n",
    "\n",
    "A corpus of documents can thus be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d0a1561-6e5c-495e-b056-fc9fe376121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53af305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectoriseX(X)\n",
    "y = y.ravel()\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02042133-9bad-4aa3-b0be-a53158e7102e",
   "metadata": {},
   "source": [
    "### Transform Testing data into a document-term matrix (using existing / training vocabulary)\n",
    "\n",
    "- You are supposed to use the training vocabolary to make the count matrix for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a50c164-91ac-4861-993d-e14a2be7c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30e0b5eb-d7ab-468a-86e2-89dcd0fa0184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9df0574c-6088-4418-92b4-d6d69c9d9d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec45268a-bc57-4a34-b496-b30751119403",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Implementation\n",
    "\n",
    "- Your task is to implement Mutlinomial Naive Bayes from scratch, you can use numpy to vectorize your code and matplotlib  to show your analysis.\n",
    "- Below some information has given from the documentation about Multinomial Naive Bayes, this will give you some idea about using *Smoothing Priors*.\n",
    "- There is a sub-question for experimenting with $\\alpha > 0$, you don't have to implement it separetely, try to incomporate it in same Model Class / Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9e325-5e71-4810-83c9-a2e3b5a547b2",
   "metadata": {},
   "source": [
    "ðŸ“Œ From the scikit-learn documentation:\n",
    "\n",
    "- Multinomial Naive Bayes implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice).\n",
    "\n",
    "- The distribution $\\theta_y = (\\theta_{y1}, \\theta_{y2}, \\dots, \\theta_{yn})$ is parametrized by vectors for each class $y$, where $n$ is the number of features (in text classification, the size of the vocabulary) and $\\theta_{yi}$ is the probability $P(x_i|y)$ of feature appearing in a sample belonging to class.\n",
    "\n",
    "- The parameters $\\theta_y$ is estimated by a smoothed version of maximum likelihood, i.e. relative frequency counting:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}_{yi} = \\frac{N_{yi} + \\alpha}{N_{y} + \\alpha n}\n",
    "$$\n",
    "\n",
    " where $N_{yi} = \\sum_{x \\in T}{x_i}$ is the number of times feature $i $ appears in a sample of class in the training set $T$, and $N_{y} = \\sum^{n}_{i=1}{N_{yi}}$ is the total count of all features for class $y$.\n",
    "\n",
    "- The smoothing priors $\\alpha \\gt 0$ accounts for features not present in the learning samples and **prevents zero probabilities** in further computations. Setting $\\alpha = 1$ is called Laplace smoothing, while $\\alpha \\lt 1$ is called Lidstone smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14862c11-1b3c-4314-a64e-f98a185ce394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour code here\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your code here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcd1df-1c3d-477d-b0f6-c8c17868c797",
   "metadata": {},
   "source": [
    "## Vectorizing Training Sample\n",
    "\n",
    "- Use the Helper code above to vectorize for training samples\n",
    "- Don't overthink it, its very easy to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0a750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiNB:\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def prior(self): \n",
    "        p = np.zeros(self.total_class_c)\n",
    "        _, dist = np.unique(self.y, return_counts=True)\n",
    "        for i in range(self.classes_.shape[0]):\n",
    "            p[i] = dist[i] / self.sample_count\n",
    "        return p\n",
    "            \n",
    "    def fit(self, X, y): \n",
    "        self.y = y\n",
    "        self.sample_count, self.feature_count = X.shape\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.total_class_c = self.classes_.shape[0]\n",
    "        self.prior_probab = self.prior()\n",
    "        \n",
    "        self.uniques = [np.unique(X[:, i]) for i in range(self.feature_count)]\n",
    "            \n",
    "        self.n_yi = np.zeros((self.total_class_c, self.feature_count)) \n",
    "        self.n_y = np.zeros(self.total_class_c) \n",
    "        for i in self.classes_:\n",
    "            # indices = np.argwhere(self.y == i).flatten()\n",
    "            self.n_yi[i] = np.sum(X[np.argwhere(self.y == i).flatten()], axis=0) \n",
    "            self.n_y[i] = np.sum(self.n_yi[i]) \n",
    "            \n",
    "    def theta(self, x_i, i, h):\n",
    "        return ((self.n_yi[h, i] + self.alpha) / (self.n_y[h] + (self.alpha * self.feature_count))) ** x_i\n",
    "    \n",
    "    def likelihood(self, x, h):\n",
    "        return np.prod([self.theta(x[i], i, h) for i in range(x.shape[0])])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        samples = X.shape[0]\n",
    "        self.predict_proba = np.zeros((samples, self.total_class_c))\n",
    "        for i in range(samples):\n",
    "            overall_likelihood = [self.prior_probab[h] * self.likelihood(X[i], h) for h in range(self.total_class_c)]\n",
    "            self.predict_proba[i] = overall_likelihood / np.sum(overall_likelihood)\n",
    "            \n",
    "        # indices = \n",
    "        return self.classes_[np.argmax(self.predict_proba, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2561b73-fc1b-47aa-8ae9-6d1ba8ad3015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour code here\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your code here\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22e087-4e03-4428-8f47-4cb4f2ec1645",
   "metadata": {},
   "source": [
    "## Calculate Priors and Estimate Model's performance on Training Sample\n",
    "\n",
    "- Calculate priors based on Training Sample using your NB implementation\n",
    "- Evaluate your model's performance on Training Data ($\\alpha = 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a05ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8eb8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb0397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1393, 7996)\n",
      "(4179, 7996)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6ec92-2ba4-40bf-9b5d-01825338c034",
   "metadata": {},
   "source": [
    "## Vectorizing Test Sample\n",
    "\n",
    "- Use the Training Sample vocabulary to create word count matrix for test samples\n",
    "- This is also shown in the Helper code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02b84a-3116-4260-846d-50e6849efe48",
   "metadata": {},
   "source": [
    "## Estimate Model's performance on Test Sample\n",
    "\n",
    "- Evaluate your model's performance on Test Sample, using the Training Priors ($\\alpha = 0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415868e-4b61-4a13-abb5-22124e5312bc",
   "metadata": {},
   "source": [
    "## Select Smoothing Priors\n",
    "\n",
    "- Refactor your code to incorporate smoothing priors, select $\\alpha = 0$ for the previous estimates / sub-questions\n",
    "- Compare the performance with different values of $\\alpha \\gt 0$ as smoothing priors to take care of zero probabilities\n",
    "- You can display a Plot or Table to show the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a707cc0d-1f16-40a5-93ec-0366165b077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1, accuracy: 0.9763101220387652\n",
      "alpha: 2, accuracy: 0.9784637473079684\n",
      "alpha: 3, accuracy: 0.9784637473079684\n",
      "alpha: 4, accuracy: 0.9777458722182341\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your code here\n",
    "\"\"\"\n",
    "li = [1,2,3,4]\n",
    "accuracy_score_list = []\n",
    "for i in li:\n",
    "    me = MultiNB(i)\n",
    "    me.fit(x_train, Y_train)\n",
    "    y_pred = me.predict(x_test)\n",
    "    accuracy_score_list.append(accuracy_score(Y_test,y_pred))\n",
    "    print(f'alpha: {i}, accuracy: {accuracy_score(Y_test,y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58051f8-67fb-4632-884b-23c719d4cae7",
   "metadata": {},
   "source": [
    "## Comparison with Sci-kit Learn Implementation\n",
    "\n",
    "- Use sci-kit learn's `sklearn.naive_bayes.MultinomialNB` model to compare your implementation's performance\n",
    "- (Optional) try other classifiers from `sklearn.naive_bayes` and see if you can make them work`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192a26af-2b0a-4165-9d36-b5ed774c11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your code here\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "li = [1,2,3,4]\n",
    "accuracy_score_list_sk = []\n",
    "\n",
    "for i in li:\n",
    "    clf = MultinomialNB(force_alpha=True,alpha=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy_score_list_sk.append(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd8ac44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplha\tMNB \t\t\tSklearnMNB\n",
      "-----\t------------------\t------------------\n",
      "1\t0.9763101220387652\t0.9827709978463748\n",
      "2\t0.9784637473079684\t0.9834888729361091\n",
      "3\t0.9784637473079684\t0.9806173725771715\n",
      "4\t0.9777458722182341\t0.9806173725771715\n"
     ]
    }
   ],
   "source": [
    "print('Aplha\\tMNB \\t\\t\\tSklearnMNB')\n",
    "print('-----\\t------------------\\t------------------')\n",
    "\n",
    "# Loop over the lists and print each row\n",
    "c = 1\n",
    "for ac, acsk in zip(accuracy_score_list, accuracy_score_list_sk):\n",
    "    print(f'{c}\\t{ac}\\t{acsk}')\n",
    "    c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f9a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
